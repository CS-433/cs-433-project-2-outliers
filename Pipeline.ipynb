{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import scipy.io as sio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#input_dim = TrainX.shape[1]\n",
    "hidden_dim = 10\n",
    "n_layers = 1\n",
    "\n",
    "seq_len = 1\n",
    "# IDEA /  try one-hot encoding see if it improves anything \n",
    "\n",
    "# check if GPU is available, (useful when we'll have access to the lab's GPU)\n",
    "\n",
    "# build the class for the model of NN \n",
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, TrainX, TrainY, n_hidden= 10 ,n_layers = 1, lr=0.001): # no dropout for now \n",
    "        super().__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "        self.n_layers = n_layers\n",
    "        self.input_dim = TrainX.shape[1]\n",
    "\n",
    "        \"\"\"self.net = nn.Sequential(nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True), \n",
    "                         nn.LSTM(hidden_dim, hidden_dim, n_layers, batch_first=True), \n",
    "                        nn.Linear(n_hidden, (TrainY.shape[1])))\"\"\"\n",
    "        #lstm layers\n",
    "        self.lstm = nn.LSTM(self.input_dim, hidden_dim, n_layers, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim, n_layers, batch_first=True)\n",
    "        #output layer\n",
    "        self.fc = nn.Linear(n_hidden, (TrainY.shape[1]))\n",
    "    \n",
    "    def binarize_weights(self, ind_layer) : \n",
    "        weights = self.net[ind_layer].weight_ih_l[0] \n",
    "        for w in weights : \n",
    "            if w >= 0 : \n",
    "                w = 1\n",
    "            else : \n",
    "                w = -1 \n",
    "        self.net[ind_layer].weight_ih_l[k]  = weights \n",
    "\n",
    "    \n",
    "    def forward(self, TrainX, hidden):\n",
    "        ''' Forward pass through the network. \n",
    "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
    "        ## Get the outputs and the new hidden state from the lstm\n",
    "        TrainX = TrainX.reshape([seq_len, TrainX.shape[0],TrainX.shape[1]])\n",
    "        #self.binarize_weights(0)\n",
    "        r_output, hidden = self.lstm(TrainX, hidden)\n",
    "        #self.binarize_weights(1)\n",
    "        r_output, hidden = self.lstm2(r_output, hidden)\n",
    "        # Stack up LSTM outputs using view\n",
    "        # reshape the output\n",
    "        out = r_output.contiguous().view(-1, self.n_hidden)\n",
    "        \n",
    "        ## put x through the fully-connected layer\n",
    "        #self.binarize_weights(2)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        hidden_state = torch.randn(n_layers, 1, hidden_dim)\n",
    "        cell_state = torch.randn(n_layers, 1, hidden_dim)\n",
    "        hidden = (hidden_state, cell_state)\n",
    "\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(TrainX, TrainY, net, lossfunc, optimizer, num_epoch, clip = 5):\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        # TODO: Step 1 - create torch variables corresponding to features and labels\n",
    "        \n",
    "        x = TrainX.reshape([seq_len, TrainX.shape[0],TrainX.shape[1]])\n",
    "        x = torch.from_numpy(TrainX).float()\n",
    "        y = torch.from_numpy(TrainY).float()\n",
    "        \n",
    "        # initialize hidden state \n",
    "        h = net.init_hidden()\n",
    "        # TODO: Step 2 - compute model predictions and loss\n",
    "        pred, h = net(x, h)\n",
    "        \n",
    "        #target = torch.reshape(y, (-1,)).long()\n",
    "        loss = lossfunc(pred, y)\n",
    "        # TODO: Step 3 - do a backward pass and a gradient update step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # gradient clipping - prevents gradient explosion \n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch == num_epoch-1:\n",
    "            #print ('Epoch [%d/%d], Loss: %.4f' %(epoch+1, num_epoch, loss.item()))\n",
    "            #vec = torch.cat((y,pred),1)\n",
    "            #vec = vec.detach().numpy()\n",
    "            corrcoef = np.corrcoef(pred.detach().numpy().reshape((-1,)),y.detach().numpy().reshape((-1,)))\n",
    "            print ('Epoch [%d/%d], Loss: %.4f' %(epoch+1, num_epoch, loss.item()))\n",
    "            print ('Correlation coefficient : {corrcoef}'.format(corrcoef=corrcoef))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run for finger  0\n",
      "Epoch [10/10], Loss: 0.2341\n",
      "Correlation coefficient : [[ 1.         -0.00686595]\n",
      " [-0.00686595  1.        ]]\n",
      "run for finger  1\n",
      "Epoch [10/10], Loss: 0.5660\n",
      "Correlation coefficient : [[1.         0.00342156]\n",
      " [0.00342156 1.        ]]\n",
      "run for finger  2\n",
      "Epoch [10/10], Loss: 0.3955\n",
      "Correlation coefficient : [[ 1.         -0.00285423]\n",
      " [-0.00285423  1.        ]]\n",
      "run for finger  3\n",
      "Epoch [10/10], Loss: 0.2555\n",
      "Correlation coefficient : [[ 1.         -0.04768108]\n",
      " [-0.04768108  1.        ]]\n",
      "run for finger  4\n",
      "Epoch [10/10], Loss: 0.3139\n",
      "Correlation coefficient : [[1.         0.02943972]\n",
      " [0.02943972 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Train model \n",
    "\n",
    "n_hidden = 10\n",
    "n_layers = 1\n",
    "\n",
    "n_epochs =  10 # start small \n",
    "\n",
    "#input_dim = TrainX.shape[1]\n",
    "# train the model\n",
    "Finger = [0,1,2,3,4]\n",
    "Idx_subject = 10\n",
    "\n",
    "\n",
    "def create_Seq_data_set(data_set, look_back):\n",
    "    data_x = []\n",
    "    data_y = []\n",
    "    for i in range(len(data_set - look_back-1)):\n",
    "        a = data_set[i:(i+look_back),0]\n",
    "        data_x.append(a)\n",
    "        data_y.append(data_set[i+look_back,0])\n",
    "    return np.array(data_x), np.array(data_y)\n",
    "        \n",
    "#prepare train and test data\n",
    "for Finger in list([0,1,2,3,4]): # 5 fingers for each subject. 0:thumb, 1:index, 2:middle ...\n",
    "    matData = sio.loadmat('data/BCImoreData_Subj_'+str(Idx_subject)+'_200msLMP.mat')\n",
    "    TrainX = matData['Data_Feature'].transpose()\n",
    "    TrainY = matData['SmoothedFinger']\n",
    "    TrainY = TrainY [:,Finger]\n",
    "    TrainY = TrainY.reshape(TrainY.shape[0],1)\n",
    "    #load testing data (TestX: feature vectors, TestY: labels)\n",
    "    matData = sio.loadmat('data/BCImoreData_Subj_'+str(Idx_subject)+'_200msLMPTest.mat')\n",
    "    TestX = matData['Data_Feature'].transpose()\n",
    "    TestY = matData['SmoothedFinger']\n",
    "    TestY = TestY[:,Finger]\n",
    "    TestY = TestY.reshape(TestY.shape[0],1)\n",
    "\n",
    "    print(\"run for finger \", Finger)\n",
    "\n",
    "    net = LSTM(TrainX, TrainY,  n_hidden, n_layers)\n",
    "\n",
    "    lossfunc = nn.L1Loss()\n",
    "    #lossfunc = nn.NLLLoss()\n",
    "    optimizer = torch.optim.Adamax(net.parameters())\n",
    "    train(TrainX, TrainY, net, lossfunc, optimizer, n_epochs, clip = 5)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
