{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio \n",
    "from preprocessing_funcs import get_spikes_with_history\n",
    "from LSTM import LSTM\n",
    "from train import train\n",
    "import torch.nn as nn\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, TrainX, TrainY, n_hidden= 10 ,n_layers = 1, lr=0.001): # no dropout for now \n",
    "        super().__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "        self.n_layers = n_layers\n",
    "        self.input_dim = TrainX.shape[2]\n",
    "        self.output_dim = TrainY.shape[1]\n",
    "        self.seq_len = TrainX.shape[1]\n",
    "\n",
    "        \"\"\"self.net = nn.Sequential(nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True), \n",
    "                         nn.LSTM(hidden_dim, hidden_dim, n_layers, batch_first=True), \n",
    "                        nn.Linear(n_hidden, (TrainY.shape[1])))\"\"\"\n",
    "        #lstm layers\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.n_hidden, self.n_layers, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(self.n_hidden, self.n_hidden, self.n_layers, batch_first=True)\n",
    "        #output layer\n",
    "        self.fc = nn.Linear(self.n_hidden, (self.output_dim))\n",
    "    \n",
    "    def binarize_weights(self, ind_layer) : \n",
    "        weights = self.net[ind_layer].weight_ih_l[0] \n",
    "        for w in weights : \n",
    "            if w >= 0 : \n",
    "                w = 1\n",
    "            else : \n",
    "                w = -1 \n",
    "        self.net[ind_layer].weight_ih_l[k]  = weights \n",
    "\n",
    "    \n",
    "    def forward(self, TrainX, hidden):\n",
    "        ''' Forward pass through the network. \n",
    "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
    "        ## Get the outputs and the new hidden state from the lstm\n",
    "        #TrainX = TrainX.reshape([self.seq_len, TrainX.shape[0],TrainX.shape[1]])\n",
    "        #self.binarize_weights(0)\n",
    "        r_output, hidden = self.lstm(TrainX, hidden)\n",
    "        #self.binarize_weights(1)\n",
    "        r_output, hidden = self.lstm2(r_output, hidden)\n",
    "        # Stack up LSTM outputs using view\n",
    "        # reshape the output\n",
    "        out = r_output.contiguous().view(-1, self.n_hidden)\n",
    "        \n",
    "        ## put x through the fully-connected layer\n",
    "        #self.binarize_weights(2)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        hidden_state = torch.randn(n_layers, 1, self.n_hidden)\n",
    "        cell_state = torch.randn(n_layers, 1, self.n_hidden)\n",
    "        hidden = (hidden_state, cell_state)\n",
    "\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(TrainX, TrainY, net, lossfunc, optimizer, num_epoch, clip = 5):\n",
    "    seq_len = TrainX.shape[1]\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        # TODO: Step 1 - create torch variables corresponding to features and labels\n",
    "        \n",
    "\n",
    "        #x = TrainX.reshape([seq_len, TrainX.shape[0],TrainX.shape[1]])\n",
    "        x = torch.from_numpy(TrainX).float()\n",
    "        y = torch.from_numpy(TrainY).float()\n",
    "        \n",
    "        # initialize hidden state \n",
    "        h = net.init_hidden()\n",
    "        # TODO: Step 2 - compute model predictions and loss\n",
    "        pred, h = net(x, h)\n",
    "        \n",
    "        #target = torch.reshape(y, (-1,)).long()\n",
    "        loss = lossfunc(pred, y)\n",
    "        # TODO: Step 3 - do a backward pass and a gradient update step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # gradient clipping - prevents gradient explosion \n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch == num_epoch-1:\n",
    "            #print ('Epoch [%d/%d], Loss: %.4f' %(epoch+1, num_epoch, loss.item()))\n",
    "            #vec = torch.cat((y,pred),1)\n",
    "            #vec = vec.detach().numpy()\n",
    "            corrcoef = np.corrcoef(pred.detach().numpy().reshape((-1,)),y.detach().numpy().reshape((-1,)))\n",
    "            print ('Epoch [%d/%d], Loss: %.4f' %(epoch+1, num_epoch, loss.item()))\n",
    "            print ('Correlation coefficient : {corrcoef}'.format(corrcoef=corrcoef))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run for finger  0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[21, 9976, 21]' is invalid for input of size 116898768",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-00740167e0d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;31m#lossfunc = nn.NLLLoss()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdamax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrainY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlossfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m             \u001b[1;31m# Preprocess the data may leed to better performance. e.g. StandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-2d087ffbfd2c>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(TrainX, TrainY, net, lossfunc, optimizer, num_epoch, clip)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# TODO: Step 2 - compute model predictions and loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m#target = torch.reshape(y, (-1,)).long()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\caffe\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-e855d2f95de2>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, TrainX, hidden)\u001b[0m\n\u001b[0;32m     33\u001b[0m             These inputs are x, and the hidden/cell state `hidden`. '''\n\u001b[0;32m     34\u001b[0m         \u001b[1;31m## Get the outputs and the new hidden state from the lstm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mTrainX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrainX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrainX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTrainX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[1;31m#self.binarize_weights(0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mr_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[21, 9976, 21]' is invalid for input of size 116898768"
     ]
    }
   ],
   "source": [
    "for Idx_subject in list([10]):#,11,12]): # 3 subjects index 10-12\n",
    "        for Finger in list([0,1,2,3,4]): # 5 fingers for each subject. 0:thumb, 1:index, 2:middle ...\n",
    "\n",
    "            #load training data (TrainX: feature vectors, TrainY: labels)\n",
    "            matData = sio.loadmat('data/BCImoreData_Subj_'+str(Idx_subject)+'_200msLMP.mat')\n",
    "            TrainX = matData['Data_Feature'].transpose()\n",
    "            TrainY = matData['SmoothedFinger']\n",
    "            TrainY = TrainY [:,Finger]\n",
    "            TrainY = TrainY.reshape(TrainY.shape[0],1)\n",
    "            #load testing data (TestX: feature vectors, TestY: labels)\n",
    "            matData = sio.loadmat('data/BCImoreData_Subj_'+str(Idx_subject)+'_200msLMPTest.mat')\n",
    "            TestX = matData['Data_Feature'].transpose()\n",
    "            TestY = matData['SmoothedFinger']\n",
    "            TestY = TestY[:,Finger]\n",
    "            TestY = TestY.reshape(TestY.shape[0],1)\n",
    "            \n",
    "            \n",
    "            \n",
    "            # from here, we reconstruct the input by \"looking back\" a few steps\n",
    "            bins_before= 20 #How many bins of neural data prior to the output are used for decoding\n",
    "            bins_current=1 #Whether to use concurrent time bin of neural data\n",
    "            bins_after=0 #How many bins of neural data after the output are used for decoding\n",
    "            \n",
    "            TrainX=get_spikes_with_history(TrainX,bins_before,bins_after,bins_current)\n",
    "            TrainX, TrainY = TrainX[bins_before:,:,:], TrainY[bins_before:,]\n",
    "            \n",
    "            TestX=get_spikes_with_history(TestX,bins_before,bins_after,bins_current)\n",
    "            TestX, TestY = TestX[bins_before:,:,:], TestY[bins_before:,]\n",
    "            \n",
    "            # Now, we reconstructed TrainX/TestX to have a shape (num_of_samples, sequence_length, input_size)\n",
    "            # You can fit this to the LSTM\n",
    "\n",
    "            print(\"run for finger \", Finger)\n",
    "\n",
    "            n_hidden = 10\n",
    "            n_layers = 1\n",
    "            n_epochs =  10 # start small \n",
    "\n",
    "            net = LSTM(TrainX, TrainY,  n_hidden, n_layers)\n",
    "\n",
    "            lossfunc = nn.L1Loss()\n",
    "            #lossfunc = nn.NLLLoss()\n",
    "            optimizer = torch.optim.Adamax(net.parameters())\n",
    "            train(TrainX, TrainY, net, lossfunc, optimizer, n_epochs, clip = 5)\n",
    "            # Preprocess the data may leed to better performance. e.g. StandardScaler \n",
    "\n",
    "\n",
    "              \n",
    "       \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
